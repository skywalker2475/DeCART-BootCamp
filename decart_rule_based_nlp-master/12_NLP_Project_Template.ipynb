{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now it's time to work on the final group project.  All of the pieces we've learned are integrated into this initial template to work on improving F1 measure on classification of pneumonia evidence\n",
    "\n",
    "# You are welcome to spend your time however you'd like but here are a few ideas of how to improve your system:\n",
    "* Improve targets.  Are there any False Negatives your system is missing?  Are there regular expressions that would help?\n",
    "* Improve modifiers.  Not all modifiers typically used in practice are the modifiers starter file.  Are there some to add?  Do some existing modifiers cause problems in your processing?  They can be changed or removed.\n",
    "* Improve document classification rules.  What rules work best?  What is the best \"default\" classification?\n",
    "* Consider handling of document \"sections\".  Are there certain headers or subsections which are more or less likely to contain evidence?  You could modify your own \"markup\" function to do this or you could add Modifiers to do this in some cases\n",
    "\n",
    "# Also before we get going, a few Pro Tips:\n",
    "* Remember that pyConText files need to be tab delimited.  If you edit these files in JupyterHub, it might be difficult to see the tabs and if you press \"TAB\" you will actually get spaces, so try to use Copy-and-Paste\n",
    "* Classification rules and modifiers are difficult.  Don't be afraid to ask for help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import everything that we will need\n",
    "import pyConTextNLP\n",
    "from pyConTextNLP import pyConTextGraph\n",
    "from pyConTextNLP.itemData import itemData\n",
    "from pyConTextNLP.display.html import mark_document_with_html\n",
    "import os\n",
    "import os.path\n",
    "# useful utilities in RadNLP as well\n",
    "import radnlp\n",
    "import radnlp.view as rview\n",
    "from radnlp.data import classrslts\n",
    "# our utilities from the class\n",
    "from nlp_pneumonia_utils import Annotation\n",
    "from nlp_pneumonia_utils import AnnotatedDocument\n",
    "from nlp_pneumonia_utils import read_brat_annotations\n",
    "from nlp_pneumonia_utils import read_doc_annotations\n",
    "from nlp_pneumonia_utils import read_annotations\n",
    "from nlp_pneumonia_utils import calculate_prediction_metrics\n",
    "from nlp_pneumonia_utils import mark_text\n",
    "from nlp_pneumonia_utils import clearPyConTextRegularExpressions\n",
    "from nlp_pneumonia_utils import pneumonia_annotation_html_markup\n",
    "from nlp_pneumonia_utils import mark_document_with_html\n",
    "from nlp_pneumonia_utils import view_single_sentence_graph\n",
    "from nlp_pneumonia_utils import markup_sentence\n",
    "from nlp_pneumonia_utils import markup_context_document\n",
    "from nlp_pneumonia_utils import DocumentClassifier\n",
    "# packages for interaction\n",
    "from IPython.html.widgets import interact, interactive, fixed\n",
    "from IPython.display import display, HTML, Image\n",
    "import ipywidgets\n",
    "print('Everything imported')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load our training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "annotated_doc_map = read_doc_annotations('data/training_v2.zip')\n",
    "\n",
    "# let's also use a simple list of documents as well as this map\n",
    "annotated_docs = list(annotated_doc_map.values())\n",
    "\n",
    "print('Total Annotated Documents : {0}'.format(len(annotated_docs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up our resources\n",
    "You're welcome to start new files or continue in the files we've used, but let's set up some defaults we have used in the course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TARGETS_FILE_PATH = 'file:///' + os.path.join(os.getcwd(), 'KB/pneumonia_targets.tsv')\n",
    "MODIFIERS_FILE_PATH = 'file:///' + os.path.join(os.getcwd(),'KB/pneumonia_modifiers.tsv')\n",
    "CLASSIFIER_FILE_PATH = 'KB/classifierRules.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load our targets and resources now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clear just in case files/regular expressions have been updated\n",
    "clearPyConTextRegularExpressions()\n",
    "\n",
    "targets = pyConTextNLP.itemData.instantiateFromCSVtoitemData(TARGETS_FILE_PATH)\n",
    "modifiers = pyConTextNLP.itemData.instantiateFromCSVtoitemData(MODIFIERS_FILE_PATH)\n",
    "\n",
    "print('Targets loaded : {0}'.format(len(targets)))\n",
    "print('Modifiers loaded : {0}'.format(len(modifiers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct our Document Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "debug_classifier = False\n",
    "docClassifier = DocumentClassifier(CLASSIFIER_FILE_PATH, debug_classifier, modifiers, targets) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's attempt some predictions\n",
    "* You will do a lot of iterations modifying content and then coming back here to check performane\n",
    "* Remember : the prediction function passed here passes in a string (text) and returns a 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('****************')\n",
    "print('Performance for Classifier :')\n",
    "calculate_prediction_metrics(annotated_docs, docClassifier.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Development of your system:\n",
    "* We have found the tools below for highlighting and graphing False Positives and False Negatives to be very useful.  We've provided them below in case it helps you as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOTE : You may need to modify this color mapping if you add  Target or Modifier categories not found here\n",
    "# prepare some colors for displaying any markup we might see\n",
    "colors = {\n",
    "    \"evidence_of_pneumonia\": \"orange\",\n",
    "    \"definite_negated_existence\": \"red\",\n",
    "    \"probable_negated_existence\": \"indianred\",\n",
    "    \"ambivalent_existence\": \"orange\",\n",
    "    \"probable_existence\": \"forestgreen\",\n",
    "    \"definite_existence\": \"green\",\n",
    "    \"historical\": \"goldenrod\",\n",
    "    \"indication\": \"pink\",\n",
    "    \"acute\": \"golden\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function let's us iterate through all documents and view the markup\n",
    "def view_pycontext_graph(class_results, colors):\n",
    "    @interact(i=ipywidgets.IntSlider(min=0, max=len(class_results)-1))\n",
    "    def _view_markup(i):\n",
    "        class_result = class_results[i]\n",
    "        rview.markup_to_pydot(class_result)\n",
    "        display(Image(\"tmp.png\"))\n",
    "        \n",
    "        report_html = mark_document_with_html(class_result.context_document, colors = colors, default_color=\"black\")\n",
    "        \n",
    "        display(HTML(report_html))\n",
    "        \n",
    "# This function let's us iterate through all documents and view the markup\n",
    "def view_annotation_markup(anno_docs, colors):\n",
    "    @interact(i=ipywidgets.IntSlider(min=0, max=len(anno_docs)-1))\n",
    "    def _view_markup(i):\n",
    "        report_html = pneumonia_annotation_html_markup(anno_docs[i])\n",
    "        \n",
    "        display(HTML(report_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list_false_negatives(gold_docs, prediction_function):\n",
    "    fn_docs={}\n",
    "    for doc_name, gold_doc in gold_docs.items():\n",
    "        gold_label=gold_doc.positive_label;\n",
    "        pred_label = prediction_function(gold_doc.text)\n",
    "        if gold_label==1 and pred_label==0:\n",
    "            fn_docs[doc_name]=gold_doc            \n",
    "    return fn_docs  \n",
    "\n",
    "def list_false_positives(gold_docs, prediction_function):\n",
    "    fn_docs={}\n",
    "    for doc_name, gold_doc in gold_docs.items():\n",
    "        gold_label=gold_doc.positive_label;\n",
    "        pred_label = prediction_function(gold_doc.text)\n",
    "        if gold_label==0 and pred_label==1:\n",
    "            fn_docs[doc_name]=gold_doc            \n",
    "    return fn_docs  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# get our current set of false negatives and false positives if we use our simple toy classifier\n",
    "# which uses targets and a simplified implementation of modifiers\n",
    "current_false_negatives = list_false_negatives(annotated_doc_map, docClassifier.predict)\n",
    "current_false_positives = list_false_positives(annotated_doc_map, docClassifier.predict)\n",
    "\n",
    "# prepare each of these for visualization\n",
    "fn_report_results = []\n",
    "fp_report_results = []\n",
    "print('Marking up False Negatives')\n",
    "for anno_doc in current_false_negatives.values():\n",
    "    report_context = markup_context_document(anno_doc.text, modifiers, targets)\n",
    "    # package this up into a class that the RadNLP utilities can use\n",
    "    results = classrslts(context_document=report_context, exam_type=\"Chest X-Ray\", report_text=anno_doc.text, classification_result='N/A')\n",
    "    fn_report_results.append(results)\n",
    "    \n",
    "print('Marking up False Positives')\n",
    "for anno_doc in current_false_positives.values():\n",
    "    report_context = markup_context_document(anno_doc.text, modifiers, targets)\n",
    "    # package this up into a class that the RadNLP utilities can use\n",
    "    results = classrslts(context_document=report_context, exam_type=\"Chest X-Ray\", report_text=anno_doc.text, classification_result='N/A')\n",
    "    fp_report_results.append(results)\n",
    "\n",
    "print('Current total False Negatives : {0}'.format(len(current_false_negatives)))\n",
    "print('Current total False Positives : {0}'.format(len(current_false_positives)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For False Negatives, it's most useful to see the expert span annotations for positive pneumonia evidence to see if there may be targets that should be added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "view_pycontext_graph(fn_report_results, colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For False Positives, it's most useful to see a pyConText graph since there may need to be modifiers adjusted so that targets can be properly utilized in classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "view_pycontext_graph(fp_report_results, colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# TEST SET Evaluation \n",
    "* We've been waiting for the test set.  It will not be available until the morning of the final class session.\n",
    "* At that time, you can uncomment this code and make any changes to it as instructed by the class instructors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test_doc_map = read_doc_annotations('data/training_v2.zip')\n",
    "\n",
    "# let's also use a simple list of documents as well as this map\n",
    "#test_docs = list(test_doc_map.values())\n",
    "\n",
    "#print('Total Test Documents : {0}'.format(len(test_docs)))\n",
    "\n",
    "# and now let's check performance on the TEST set...\n",
    "#print('****************')\n",
    "#print('Performance for Classifier on TEST set :')\n",
    "#calculate_prediction_metrics(test_docs, docClassifier.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>This material presented as part of the DeCART Data Science for the Health Science Summer Program at the University of Utah in 2017.<br/>\n",
    "Presenters : Dr. Wendy Chapman, Jianlin Shi and Kelly Peterson"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
